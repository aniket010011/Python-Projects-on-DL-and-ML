{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r0BYGOEnmKQV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgbm\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import make_blobs\n",
        "from collections import Counter\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import classification_report, fbeta_score, precision_score, recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_train = '/content/carvan_train.csv'\n",
        "file_test = '/content/carvan_test.csv'\n",
        "df_train = pd.read_csv(file_train)\n",
        "df_test = pd.read_csv(file_test)"
      ],
      "metadata": {
        "id": "rxLA9Q9gVGqQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the datasets for train and test and checking for nan values"
      ],
      "metadata": {
        "id": "goORbznQHoF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b4eEbb3mV94-",
        "outputId": "c7024058-4795-4c9c-dc29-61a1af66f727"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V77  V78  V79  V80  V81  \\\n",
              "0     33   1   3   2   8   0   5   1   3    7  ...    0    0    0    1    0   \n",
              "1     37   1   2   2   8   1   4   1   4    6  ...    0    0    0    1    0   \n",
              "2     37   1   2   2   8   0   4   2   4    3  ...    0    0    0    1    0   \n",
              "3      9   1   3   3   3   2   3   2   4    5  ...    0    0    0    1    0   \n",
              "4     40   1   4   2  10   1   4   1   4    7  ...    0    0    0    1    0   \n",
              "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
              "5817  36   1   1   2   8   0   6   1   2    1  ...    0    0    0    1    0   \n",
              "5818  35   1   4   4   8   1   4   1   4    6  ...    0    0    0    1    0   \n",
              "5819  33   1   3   4   8   0   6   0   3    5  ...    0    0    0    1    0   \n",
              "5820  34   1   3   2   8   0   7   0   2    7  ...    0    0    0    0    0   \n",
              "5821  33   1   3   3   8   0   6   1   2    7  ...    0    0    0    0    0   \n",
              "\n",
              "      V82  V83  V84  V85  V86  \n",
              "0       0    0    0    0    0  \n",
              "1       0    0    0    0    0  \n",
              "2       0    0    0    0    0  \n",
              "3       0    0    0    0    0  \n",
              "4       0    0    0    0    0  \n",
              "...   ...  ...  ...  ...  ...  \n",
              "5817    0    0    0    0    0  \n",
              "5818    0    0    0    0    0  \n",
              "5819    0    0    0    0    1  \n",
              "5820    0    0    0    0    0  \n",
              "5821    0    0    0    0    0  \n",
              "\n",
              "[5822 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f37908b3-3a11-49f6-97bf-79d2337bc40c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V77</th>\n",
              "      <th>V78</th>\n",
              "      <th>V79</th>\n",
              "      <th>V80</th>\n",
              "      <th>V81</th>\n",
              "      <th>V82</th>\n",
              "      <th>V83</th>\n",
              "      <th>V84</th>\n",
              "      <th>V85</th>\n",
              "      <th>V86</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5817</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5818</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5820</th>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5821</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5822 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f37908b3-3a11-49f6-97bf-79d2337bc40c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f37908b3-3a11-49f6-97bf-79d2337bc40c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f37908b3-3a11-49f6-97bf-79d2337bc40c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9b9f4965-7b26-421c-9521-99ed449670d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b9f4965-7b26-421c-9521-99ed449670d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9b9f4965-7b26-421c-9521-99ed449670d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dd8a92c8-1977-4bc4-adf8-02905a32589e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dd8a92c8-1977-4bc4-adf8-02905a32589e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_5kwDtcZWB4J",
        "outputId": "36ff9763-beb2-4cf5-bdc7-8cb9406e57be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V76  V77  V78  V79  V80  \\\n",
              "0     33   1   4   2   8   0   6   0   3    5  ...    0    0    0    0    1   \n",
              "1      6   1   3   2   2   0   5   0   4    5  ...    2    0    0    0    1   \n",
              "2     39   1   3   3   9   1   4   2   3    5  ...    1    0    0    0    1   \n",
              "3      9   1   2   3   3   2   3   2   4    5  ...    0    0    0    0    1   \n",
              "4     31   1   2   4   7   0   2   0   7    9  ...    0    0    0    0    1   \n",
              "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
              "3995  33   1   2   4   8   0   7   2   0    5  ...    0    0    0    0    1   \n",
              "3996  24   1   2   3   5   1   5   1   3    4  ...    1    0    0    0    1   \n",
              "3997  36   1   2   3   8   1   5   1   3    7  ...    0    0    0    0    1   \n",
              "3998  33   1   3   3   8   1   4   2   3    7  ...    0    0    0    0    0   \n",
              "3999   8   1   2   3   2   4   3   0   3    5  ...    0    0    0    0    1   \n",
              "\n",
              "      V81  V82  V83  V84  V85  \n",
              "0       0    0    0    0    0  \n",
              "1       0    0    0    0    0  \n",
              "2       0    0    0    0    0  \n",
              "3       0    0    0    0    0  \n",
              "4       0    0    0    0    0  \n",
              "...   ...  ...  ...  ...  ...  \n",
              "3995    0    0    0    0    0  \n",
              "3996    0    0    0    0    0  \n",
              "3997    0    0    0    1    0  \n",
              "3998    0    0    0    0    0  \n",
              "3999    0    0    0    0    0  \n",
              "\n",
              "[4000 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ed84f89-716b-472e-829c-49c094055f28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V76</th>\n",
              "      <th>V77</th>\n",
              "      <th>V78</th>\n",
              "      <th>V79</th>\n",
              "      <th>V80</th>\n",
              "      <th>V81</th>\n",
              "      <th>V82</th>\n",
              "      <th>V83</th>\n",
              "      <th>V84</th>\n",
              "      <th>V85</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ed84f89-716b-472e-829c-49c094055f28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ed84f89-716b-472e-829c-49c094055f28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ed84f89-716b-472e-829c-49c094055f28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24b4f525-527a-422d-a821-6b1fc203377a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24b4f525-527a-422d-a821-6b1fc203377a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24b4f525-527a-422d-a821-6b1fc203377a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbe09c03-6e15-4ad6-b9b3-034e5fefc56a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbe09c03-6e15-4ad6-b9b3-034e5fefc56a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLXuLbVWGnb",
        "outputId": "a00d0222-ef30-4579-d3d1-aa2de00ef2f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.False_"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "PIzmN07xWKkK",
        "outputId": "0ced1fd1-39e1-4f88-d8c9-9f8bfdf0d445"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                V1           V2           V3           V4           V5  \\\n",
              "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
              "mean     24.253349     1.110615     2.678805     2.991240     5.773617   \n",
              "std      12.846706     0.405842     0.789835     0.814589     2.856760   \n",
              "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
              "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
              "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
              "max      41.000000    10.000000     5.000000     6.000000    10.000000   \n",
              "\n",
              "                V6           V7           V8           V9          V10  ...  \\\n",
              "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  ...   \n",
              "mean      0.696496     4.626932     1.069907     3.258502     6.183442  ...   \n",
              "std       1.003234     1.715843     1.017503     1.597647     1.909482  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     4.000000     0.000000     2.000000     5.000000  ...   \n",
              "50%       0.000000     5.000000     1.000000     3.000000     6.000000  ...   \n",
              "75%       1.000000     6.000000     2.000000     4.000000     7.000000  ...   \n",
              "max       9.000000     9.000000     5.000000     9.000000     9.000000  ...   \n",
              "\n",
              "               V77          V78          V79          V80          V81  \\\n",
              "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
              "mean      0.005325     0.006527     0.004638     0.570079     0.000515   \n",
              "std       0.072782     0.080532     0.077403     0.562058     0.022696   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
              "max       1.000000     1.000000     2.000000     7.000000     1.000000   \n",
              "\n",
              "               V82          V83          V84          V85          V86  \n",
              "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  \n",
              "mean      0.006012     0.031776     0.007901     0.014256     0.059773  \n",
              "std       0.081632     0.210986     0.090463     0.119996     0.237087  \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "max       2.000000     3.000000     2.000000     2.000000     1.000000  \n",
              "\n",
              "[8 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e905a7ea-4e19-449a-8b85-07898093b7c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V77</th>\n",
              "      <th>V78</th>\n",
              "      <th>V79</th>\n",
              "      <th>V80</th>\n",
              "      <th>V81</th>\n",
              "      <th>V82</th>\n",
              "      <th>V83</th>\n",
              "      <th>V84</th>\n",
              "      <th>V85</th>\n",
              "      <th>V86</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "      <td>5822.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24.253349</td>\n",
              "      <td>1.110615</td>\n",
              "      <td>2.678805</td>\n",
              "      <td>2.991240</td>\n",
              "      <td>5.773617</td>\n",
              "      <td>0.696496</td>\n",
              "      <td>4.626932</td>\n",
              "      <td>1.069907</td>\n",
              "      <td>3.258502</td>\n",
              "      <td>6.183442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005325</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>0.004638</td>\n",
              "      <td>0.570079</td>\n",
              "      <td>0.000515</td>\n",
              "      <td>0.006012</td>\n",
              "      <td>0.031776</td>\n",
              "      <td>0.007901</td>\n",
              "      <td>0.014256</td>\n",
              "      <td>0.059773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.846706</td>\n",
              "      <td>0.405842</td>\n",
              "      <td>0.789835</td>\n",
              "      <td>0.814589</td>\n",
              "      <td>2.856760</td>\n",
              "      <td>1.003234</td>\n",
              "      <td>1.715843</td>\n",
              "      <td>1.017503</td>\n",
              "      <td>1.597647</td>\n",
              "      <td>1.909482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072782</td>\n",
              "      <td>0.080532</td>\n",
              "      <td>0.077403</td>\n",
              "      <td>0.562058</td>\n",
              "      <td>0.022696</td>\n",
              "      <td>0.081632</td>\n",
              "      <td>0.210986</td>\n",
              "      <td>0.090463</td>\n",
              "      <td>0.119996</td>\n",
              "      <td>0.237087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e905a7ea-4e19-449a-8b85-07898093b7c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e905a7ea-4e19-449a-8b85-07898093b7c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e905a7ea-4e19-449a-8b85-07898093b7c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f220601d-9b37-436d-9d7a-606b8e507d62\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f220601d-9b37-436d-9d7a-606b8e507d62')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f220601d-9b37-436d-9d7a-606b8e507d62 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train.drop('V86', axis = 1)\n",
        "y = df_train['V86']"
      ],
      "metadata": {
        "id": "r3y7wKJ3c1lq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "id": "JIVys_Vgc9Zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "c0a5a260-b25a-4c1c-9feb-32f06d445c29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V86\n",
              "0    5474\n",
              "1     348\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V86</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratifying the the train data using SMOTE-TOMEK"
      ],
      "metadata": {
        "id": "KBT_JL1PFAPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 1, stratify = y)"
      ],
      "metadata": {
        "id": "NuRDS1ESXRso"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(y_train))\n",
        "print(Counter(y_test))"
      ],
      "metadata": {
        "id": "Djry8D1fE3-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f23bd2-2ddb-45f4-e8a4-e481847211b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 2737, 1: 174})\n",
            "Counter({0: 2737, 1: 174})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resampling the imbalanced data"
      ],
      "metadata": {
        "id": "7iaJV5dMFK3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smtt = SMOTETomek(random_state = 42)"
      ],
      "metadata": {
        "id": "4e6B3DEWhf3M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating lists of numerical and categorical columns"
      ],
      "metadata": {
        "id": "xFXXaCTvKSfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_num = df_train.drop(['V1', 'V5', 'V86'], axis = 1)\n",
        "X_cat = df_train[['V1','V5']]"
      ],
      "metadata": {
        "id": "0L0JqQ4Cfpa3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_num.columns.values.tolist()\n",
        "cat_cols = X_cat.columns.values.tolist()"
      ],
      "metadata": {
        "id": "XMW_ks6WguWB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_cols)\n",
        "print(cat_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5yTHMKon_-L",
        "outputId": "a5efb3e9-5d0b-45ca-8fc3-cc5bc4c0c607"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['V2', 'V3', 'V4', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85']\n",
            "['V1', 'V5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the pipelines for preprocessing and applying model"
      ],
      "metadata": {
        "id": "yi4I4imIJx-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_pipe = Pipeline(steps = [\n",
        "    ('impute', SimpleImputer(strategy = 'mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "LrEU8FMzT1Uc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_pipe = Pipeline(steps = [\n",
        "    ('impute', SimpleImputer(strategy = 'constant')),\n",
        "    ('onehot_encoder', OneHotEncoder(handle_unknown = 'ignore'))\n",
        "])"
      ],
      "metadata": {
        "id": "2Gz8ntyUcnYb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_tf = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols),\n",
        "],\n",
        "    remainder = 'drop',\n",
        ")"
      ],
      "metadata": {
        "id": "MSg305uaVen-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing PCA to see how many components are providing meaningful variance and shortlisting them for pipeline"
      ],
      "metadata": {
        "id": "oN7A4j15vSTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca1 = PCA()"
      ],
      "metadata": {
        "id": "CtmDi8m6q0ns"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe = Pipeline(steps = [\n",
        "    ('column_transformer', column_tf), ('smote', smtt), ('PCA', pca1), ('classifier', lgbm.LGBMClassifier(device=\"gpu\"))\n",
        "])"
      ],
      "metadata": {
        "id": "ItC8GnhyVW55"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "vQ4kAtYGDxhf",
        "outputId": "44e64108-0fef-443f-a066-095af7d73d1c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2733, number of negative: 2733\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 33915\n",
            "[LightGBM] [Info] Number of data points in the train set: 5466, number of used features: 133\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 133 dense feature groups (0.71 MB) transferred to GPU in 0.002000 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('column_transformer',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('impute',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['V2', 'V3', 'V4', 'V6', 'V7',\n",
              "                                                   'V8', 'V9', 'V10', 'V11',\n",
              "                                                   'V12', 'V13', 'V14', 'V15',\n",
              "                                                   'V16', 'V17', 'V18', 'V19',\n",
              "                                                   'V20', 'V21', 'V22', 'V23',\n",
              "                                                   'V24', 'V25', 'V26', 'V27',\n",
              "                                                   'V28', 'V29', 'V30', 'V31',\n",
              "                                                   'V32', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('impute',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot_encoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['V1', 'V5'])])),\n",
              "                ('smote', SMOTETomek(random_state=42)), ('PCA', PCA()),\n",
              "                ('classifier', LGBMClassifier(device='gpu'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)), (&#x27;PCA&#x27;, PCA()),\n",
              "                (&#x27;classifier&#x27;, LGBMClassifier(device=&#x27;gpu&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)), (&#x27;PCA&#x27;, PCA()),\n",
              "                (&#x27;classifier&#x27;, LGBMClassifier(device=&#x27;gpu&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>column_transformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
              "                                  &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                  &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;,\n",
              "                                  &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                  &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, ...]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                 (&#x27;onehot_encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;V1&#x27;, &#x27;V5&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, &#x27;V33&#x27;, &#x27;V34&#x27;, &#x27;V35&#x27;, &#x27;V36&#x27;, &#x27;V37&#x27;, &#x27;V38&#x27;, &#x27;V39&#x27;, &#x27;V40&#x27;, &#x27;V41&#x27;, &#x27;V42&#x27;, &#x27;V43&#x27;, &#x27;V44&#x27;, &#x27;V45&#x27;, &#x27;V46&#x27;, &#x27;V47&#x27;, &#x27;V48&#x27;, &#x27;V49&#x27;, &#x27;V50&#x27;, &#x27;V51&#x27;, &#x27;V52&#x27;, &#x27;V53&#x27;, &#x27;V54&#x27;, &#x27;V55&#x27;, &#x27;V56&#x27;, &#x27;V57&#x27;, &#x27;V58&#x27;, &#x27;V59&#x27;, &#x27;V60&#x27;, &#x27;V61&#x27;, &#x27;V62&#x27;, &#x27;V63&#x27;, &#x27;V64&#x27;, &#x27;V65&#x27;, &#x27;V66&#x27;, &#x27;V67&#x27;, &#x27;V68&#x27;, &#x27;V69&#x27;, &#x27;V70&#x27;, &#x27;V71&#x27;, &#x27;V72&#x27;, &#x27;V73&#x27;, &#x27;V74&#x27;, &#x27;V75&#x27;, &#x27;V76&#x27;, &#x27;V77&#x27;, &#x27;V78&#x27;, &#x27;V79&#x27;, &#x27;V80&#x27;, &#x27;V81&#x27;, &#x27;V82&#x27;, &#x27;V83&#x27;, &#x27;V84&#x27;, &#x27;V85&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V5&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTETomek</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTETomek(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe.feature_names_in_"
      ],
      "metadata": {
        "id": "sc5m9SB6Dv3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ad4b73-95ae-4716-a7b1-f65c9493fe4d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
              "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
              "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29',\n",
              "       'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38',\n",
              "       'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47',\n",
              "       'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56',\n",
              "       'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65',\n",
              "       'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74',\n",
              "       'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83',\n",
              "       'V84', 'V85'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(1,len(pca1.explained_variance_)+1),pca1.explained_variance_)\n",
        "plt.ylabel('Explained variance')\n",
        "plt.xlabel('Components')\n",
        "plt.plot(range(1,len(pca1.explained_variance_)+1),\n",
        "          np.cumsum(pca1.explained_variance_),\n",
        "          c='red',\n",
        "          label=\"Cumulative Explained Variance\")\n",
        "plt.legend(loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "0hlSVjYAsyFY",
        "outputId": "e9efdc4e-738a-4f97-a206-3a94d9206c06"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3ab6104d10>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca2 = PCA(n_components=15)"
      ],
      "metadata": {
        "id": "SMUMBIGfbJqj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe = Pipeline(steps = [\n",
        "    ('column_transformer', column_tf), ('smote', smtt), ('PCA', pca2), ('classifier', lgbm.LGBMClassifier(device=\"gpu\"))\n",
        "])"
      ],
      "metadata": {
        "id": "PkrkDlORbJdb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "hT0lm37QbJPN",
        "outputId": "620aa054-42e7-4f48-f73c-9447d5fbd34a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2733, number of negative: 2733\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 3825\n",
            "[LightGBM] [Info] Number of data points in the train set: 5466, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.08 MB) transferred to GPU in 0.000526 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('column_transformer',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('impute',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['V2', 'V3', 'V4', 'V6', 'V7',\n",
              "                                                   'V8', 'V9', 'V10', 'V11',\n",
              "                                                   'V12', 'V13', 'V14', 'V15',\n",
              "                                                   'V16', 'V17', 'V18', 'V19',\n",
              "                                                   'V20', 'V21', 'V22', 'V23',\n",
              "                                                   'V24', 'V25', 'V26', 'V27',\n",
              "                                                   'V28', 'V29', 'V30', 'V31',\n",
              "                                                   'V32', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('impute',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot_encoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['V1', 'V5'])])),\n",
              "                ('smote', SMOTETomek(random_state=42)),\n",
              "                ('PCA', PCA(n_components=15)),\n",
              "                ('classifier', LGBMClassifier(device='gpu'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)),\n",
              "                (&#x27;PCA&#x27;, PCA(n_components=15)),\n",
              "                (&#x27;classifier&#x27;, LGBMClassifier(device=&#x27;gpu&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)),\n",
              "                (&#x27;PCA&#x27;, PCA(n_components=15)),\n",
              "                (&#x27;classifier&#x27;, LGBMClassifier(device=&#x27;gpu&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>column_transformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
              "                                  &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                  &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;,\n",
              "                                  &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                  &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, ...]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                 (&#x27;onehot_encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;V1&#x27;, &#x27;V5&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, &#x27;V33&#x27;, &#x27;V34&#x27;, &#x27;V35&#x27;, &#x27;V36&#x27;, &#x27;V37&#x27;, &#x27;V38&#x27;, &#x27;V39&#x27;, &#x27;V40&#x27;, &#x27;V41&#x27;, &#x27;V42&#x27;, &#x27;V43&#x27;, &#x27;V44&#x27;, &#x27;V45&#x27;, &#x27;V46&#x27;, &#x27;V47&#x27;, &#x27;V48&#x27;, &#x27;V49&#x27;, &#x27;V50&#x27;, &#x27;V51&#x27;, &#x27;V52&#x27;, &#x27;V53&#x27;, &#x27;V54&#x27;, &#x27;V55&#x27;, &#x27;V56&#x27;, &#x27;V57&#x27;, &#x27;V58&#x27;, &#x27;V59&#x27;, &#x27;V60&#x27;, &#x27;V61&#x27;, &#x27;V62&#x27;, &#x27;V63&#x27;, &#x27;V64&#x27;, &#x27;V65&#x27;, &#x27;V66&#x27;, &#x27;V67&#x27;, &#x27;V68&#x27;, &#x27;V69&#x27;, &#x27;V70&#x27;, &#x27;V71&#x27;, &#x27;V72&#x27;, &#x27;V73&#x27;, &#x27;V74&#x27;, &#x27;V75&#x27;, &#x27;V76&#x27;, &#x27;V77&#x27;, &#x27;V78&#x27;, &#x27;V79&#x27;, &#x27;V80&#x27;, &#x27;V81&#x27;, &#x27;V82&#x27;, &#x27;V83&#x27;, &#x27;V84&#x27;, &#x27;V85&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V5&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTETomek</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTETomek(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=15)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning the model with class weights to get realistic outcomes for the given problem"
      ],
      "metadata": {
        "id": "H3qLScFviB16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {0:1.33, 1:1.22}"
      ],
      "metadata": {
        "id": "J-IUziBYE2_s"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Grid Search for hyperparameter tuning"
      ],
      "metadata": {
        "id": "uM9FJAJsKyfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'classifier__learning_rate': [0.005, 0.01],\n",
        "    'classifier__n_estimators': [100, 300],\n",
        "    'classifier__boosting_type': ['gbdt'],\n",
        "    'classifier__max_depth': [-1],\n",
        "    'classifier__num_leaves': [7, 15],\n",
        "    'classifier__min_child_samples': [1, 10],\n",
        "    'classifier__max_bin': [63, 127],\n",
        "    'classifier__bagging_fraction': [0.5, 0.9],\n",
        "    'classifier__class_weight': [class_weights],\n",
        "    'classifier__reg_lambda': [1, 3]\n",
        "}"
      ],
      "metadata": {
        "id": "vATtagupZEdY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)"
      ],
      "metadata": {
        "id": "_ZKE7ut8dgiT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GridSearchCV(final_pipe, param_grid = param_grid, cv=kfold, scoring=\"accuracy\")"
      ],
      "metadata": {
        "id": "jrGkCKj_lYEX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lkhuulyz3fI2",
        "outputId": "2486e034-cc73-46d1-866c-4003830a53fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000596 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000600 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000633 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000543 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000619 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000619 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000654 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000668 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000633 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000573 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000736 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000633 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000588 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000505 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000578 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000597 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000558 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000625 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000543 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000623 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000631 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000630 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000624 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000554 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000573 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000538 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000603 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000536 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000555 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000539 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000541 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000606 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000703 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000600 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000668 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000605 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000648 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000596 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000603 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000545 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000608 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000483 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000662 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000604 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000617 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000546 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000584 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000462 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000613 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000596 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000552 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000595 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000683 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000550 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000644 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000580 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000575 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000750 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000667 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000507 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000582 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000454 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000612 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000566 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000610 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000629 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000630 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000581 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000577 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000620 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000613 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000620 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000582 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000584 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000566 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000553 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000597 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.003658 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000580 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000585 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000620 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000590 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000604 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000468 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000610 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000613 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000574 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000588 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000598 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000484 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000608 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000556 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000564 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000450 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000546 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000559 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000705 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000438 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000621 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000568 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000607 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000530 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000607 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000431 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000627 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000547 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000547 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000769 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000544 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000543 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000569 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000587 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000575 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000586 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000664 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000573 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000521 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000494 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000549 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000438 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000596 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000540 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000607 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000542 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000603 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000676 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000685 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000542 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000554 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000573 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000578 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000610 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000617 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000576 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000558 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000560 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000599 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000547 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000601 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000623 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000599 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000446 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000555 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000639 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000567 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000599 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000660 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000569 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000584 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000539 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000548 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000602 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000615 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000584 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000590 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000617 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000664 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000596 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000541 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000542 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000556 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000569 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000546 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000689 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000598 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000578 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000454 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000592 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000690 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000569 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000590 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000692 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000558 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000598 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000618 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000578 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000575 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000586 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000584 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000498 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000618 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000582 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000602 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000615 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000564 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000613 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000572 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000537 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000599 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000653 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000544 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000604 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000605 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000576 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000613 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000601 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000662 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000573 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000463 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000543 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000551 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000589 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000604 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000565 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000696 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000555 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000599 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000600 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000532 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000610 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000540 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000566 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000622 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000544 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000804 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000603 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000593 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000641 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000535 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000459 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000604 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000575 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000492 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000628 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000581 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000569 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000519 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000627 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000779 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000564 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000598 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000528 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000741 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000665 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000703 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000496 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000498 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000704 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000633 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000639 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000447 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000533 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000595 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000557 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000521 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000621 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000621 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000768 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.004910 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000704 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000619 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000702 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000544 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000511 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000602 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000446 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000581 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000559 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000603 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000597 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000456 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000505 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000551 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000587 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000560 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000694 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000536 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000568 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000571 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000583 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000674 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000549 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000559 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000600 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000594 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000562 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000666 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.001099 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000582 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000614 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000552 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000612 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000561 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000652 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000548 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000564 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000597 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000741 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000541 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000545 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000542 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000543 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000551 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000616 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000525 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000570 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000734 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000554 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000555 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000442 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000565 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000591 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000554 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000536 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000619 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000648 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000552 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000597 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000628 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000567 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000706 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000590 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000601 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2188, number of negative: 2188\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4376, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000563 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000594 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000605 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Info] Number of positive: 2189, number of negative: 2189\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 1905\n",
            "[LightGBM] [Info] Number of data points in the train set: 4378, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.07 MB) transferred to GPU in 0.000579 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2733, number of negative: 2733\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 5466, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.08 MB) transferred to GPU in 0.000608 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
              "             estimator=Pipeline(steps=[('column_transformer',\n",
              "                                        ColumnTransformer(transformers=[('num',\n",
              "                                                                         Pipeline(steps=[('impute',\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         ('scaler',\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         ['V2',\n",
              "                                                                          'V3',\n",
              "                                                                          'V4',\n",
              "                                                                          'V6',\n",
              "                                                                          'V7',\n",
              "                                                                          'V8',\n",
              "                                                                          'V9',\n",
              "                                                                          'V10',\n",
              "                                                                          'V11',\n",
              "                                                                          'V12',\n",
              "                                                                          'V13',\n",
              "                                                                          'V14',\n",
              "                                                                          'V15',\n",
              "                                                                          'V16',\n",
              "                                                                          'V17',\n",
              "                                                                          'V18',\n",
              "                                                                          'V19',\n",
              "                                                                          'V20',\n",
              "                                                                          'V21',\n",
              "                                                                          'V22',\n",
              "                                                                          'V23...\n",
              "             param_grid={'classifier__bagging_fraction': [0.5, 0.9],\n",
              "                         'classifier__boosting_type': ['gbdt'],\n",
              "                         'classifier__class_weight': [{0: 1.33, 1: 1.22}],\n",
              "                         'classifier__learning_rate': [0.005, 0.01],\n",
              "                         'classifier__max_bin': [63, 127],\n",
              "                         'classifier__max_depth': [-1],\n",
              "                         'classifier__min_child_samples': [1, 10],\n",
              "                         'classifier__n_estimators': [100, 300],\n",
              "                         'classifier__num_leaves': [7, 15],\n",
              "                         'classifier__reg_lambda': [1, 3]},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
              "             estimator=Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         (&#x27;scaler&#x27;,\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         [&#x27;V2&#x27;,\n",
              "                                                                          &#x27;V3&#x27;,\n",
              "                                                                          &#x27;V4&#x27;,\n",
              "                                                                          &#x27;V6&#x27;,\n",
              "                                                                          &#x27;V7&#x27;,\n",
              "                                                                          &#x27;V8&#x27;,\n",
              "                                                                          &#x27;V9&#x27;,\n",
              "                                                                          &#x27;V10&#x27;,\n",
              "                                                                          &#x27;V11&#x27;,\n",
              "                                                                          &#x27;V12&#x27;,\n",
              "                                                                          &#x27;V13&#x27;,\n",
              "                                                                          &#x27;V14&#x27;,\n",
              "                                                                          &#x27;V15&#x27;,\n",
              "                                                                          &#x27;V16&#x27;,\n",
              "                                                                          &#x27;V17&#x27;,\n",
              "                                                                          &#x27;V18&#x27;,\n",
              "                                                                          &#x27;V19&#x27;,\n",
              "                                                                          &#x27;V20&#x27;,\n",
              "                                                                          &#x27;V21&#x27;,\n",
              "                                                                          &#x27;V22&#x27;,\n",
              "                                                                          &#x27;V23...\n",
              "             param_grid={&#x27;classifier__bagging_fraction&#x27;: [0.5, 0.9],\n",
              "                         &#x27;classifier__boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
              "                         &#x27;classifier__class_weight&#x27;: [{0: 1.33, 1: 1.22}],\n",
              "                         &#x27;classifier__learning_rate&#x27;: [0.005, 0.01],\n",
              "                         &#x27;classifier__max_bin&#x27;: [63, 127],\n",
              "                         &#x27;classifier__max_depth&#x27;: [-1],\n",
              "                         &#x27;classifier__min_child_samples&#x27;: [1, 10],\n",
              "                         &#x27;classifier__n_estimators&#x27;: [100, 300],\n",
              "                         &#x27;classifier__num_leaves&#x27;: [7, 15],\n",
              "                         &#x27;classifier__reg_lambda&#x27;: [1, 3]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
              "             estimator=Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         (&#x27;scaler&#x27;,\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         [&#x27;V2&#x27;,\n",
              "                                                                          &#x27;V3&#x27;,\n",
              "                                                                          &#x27;V4&#x27;,\n",
              "                                                                          &#x27;V6&#x27;,\n",
              "                                                                          &#x27;V7&#x27;,\n",
              "                                                                          &#x27;V8&#x27;,\n",
              "                                                                          &#x27;V9&#x27;,\n",
              "                                                                          &#x27;V10&#x27;,\n",
              "                                                                          &#x27;V11&#x27;,\n",
              "                                                                          &#x27;V12&#x27;,\n",
              "                                                                          &#x27;V13&#x27;,\n",
              "                                                                          &#x27;V14&#x27;,\n",
              "                                                                          &#x27;V15&#x27;,\n",
              "                                                                          &#x27;V16&#x27;,\n",
              "                                                                          &#x27;V17&#x27;,\n",
              "                                                                          &#x27;V18&#x27;,\n",
              "                                                                          &#x27;V19&#x27;,\n",
              "                                                                          &#x27;V20&#x27;,\n",
              "                                                                          &#x27;V21&#x27;,\n",
              "                                                                          &#x27;V22&#x27;,\n",
              "                                                                          &#x27;V23...\n",
              "             param_grid={&#x27;classifier__bagging_fraction&#x27;: [0.5, 0.9],\n",
              "                         &#x27;classifier__boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
              "                         &#x27;classifier__class_weight&#x27;: [{0: 1.33, 1: 1.22}],\n",
              "                         &#x27;classifier__learning_rate&#x27;: [0.005, 0.01],\n",
              "                         &#x27;classifier__max_bin&#x27;: [63, 127],\n",
              "                         &#x27;classifier__max_depth&#x27;: [-1],\n",
              "                         &#x27;classifier__min_child_samples&#x27;: [1, 10],\n",
              "                         &#x27;classifier__n_estimators&#x27;: [100, 300],\n",
              "                         &#x27;classifier__num_leaves&#x27;: [7, 15],\n",
              "                         &#x27;classifier__reg_lambda&#x27;: [1, 3]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(step...\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)),\n",
              "                (&#x27;PCA&#x27;, PCA(n_components=15)),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 LGBMClassifier(bagging_fraction=0.5,\n",
              "                                class_weight={0: 1.33, 1: 1.22}, device=&#x27;gpu&#x27;,\n",
              "                                learning_rate=0.01, max_bin=63,\n",
              "                                min_child_samples=1, n_estimators=300,\n",
              "                                num_leaves=15, reg_lambda=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>column_transformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
              "                                  &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                  &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;,\n",
              "                                  &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                  &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, ...]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                 (&#x27;onehot_encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;V1&#x27;, &#x27;V5&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, &#x27;V33&#x27;, &#x27;V34&#x27;, &#x27;V35&#x27;, &#x27;V36&#x27;, &#x27;V37&#x27;, &#x27;V38&#x27;, &#x27;V39&#x27;, &#x27;V40&#x27;, &#x27;V41&#x27;, &#x27;V42&#x27;, &#x27;V43&#x27;, &#x27;V44&#x27;, &#x27;V45&#x27;, &#x27;V46&#x27;, &#x27;V47&#x27;, &#x27;V48&#x27;, &#x27;V49&#x27;, &#x27;V50&#x27;, &#x27;V51&#x27;, &#x27;V52&#x27;, &#x27;V53&#x27;, &#x27;V54&#x27;, &#x27;V55&#x27;, &#x27;V56&#x27;, &#x27;V57&#x27;, &#x27;V58&#x27;, &#x27;V59&#x27;, &#x27;V60&#x27;, &#x27;V61&#x27;, &#x27;V62&#x27;, &#x27;V63&#x27;, &#x27;V64&#x27;, &#x27;V65&#x27;, &#x27;V66&#x27;, &#x27;V67&#x27;, &#x27;V68&#x27;, &#x27;V69&#x27;, &#x27;V70&#x27;, &#x27;V71&#x27;, &#x27;V72&#x27;, &#x27;V73&#x27;, &#x27;V74&#x27;, &#x27;V75&#x27;, &#x27;V76&#x27;, &#x27;V77&#x27;, &#x27;V78&#x27;, &#x27;V79&#x27;, &#x27;V80&#x27;, &#x27;V81&#x27;, &#x27;V82&#x27;, &#x27;V83&#x27;, &#x27;V84&#x27;, &#x27;V85&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V5&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTETomek</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTETomek(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=15)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.5, class_weight={0: 1.33, 1: 1.22},\n",
              "               device=&#x27;gpu&#x27;, learning_rate=0.01, max_bin=63,\n",
              "               min_child_samples=1, n_estimators=300, num_leaves=15,\n",
              "               reg_lambda=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.best_params_"
      ],
      "metadata": {
        "id": "Btg-bWaepemo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91008cd-a430-43b2-e831-3c944815ae6f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__bagging_fraction': 0.5,\n",
              " 'classifier__boosting_type': 'gbdt',\n",
              " 'classifier__class_weight': {0: 1.33, 1: 1.22},\n",
              " 'classifier__learning_rate': 0.01,\n",
              " 'classifier__max_bin': 63,\n",
              " 'classifier__max_depth': -1,\n",
              " 'classifier__min_child_samples': 1,\n",
              " 'classifier__n_estimators': 300,\n",
              " 'classifier__num_leaves': 15,\n",
              " 'classifier__reg_lambda': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score=clf.best_estimator_.predict_proba(X_train)\n",
        "train_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PchaCxaV1DOL",
        "outputId": "48654f44-afe4-44b4-fec1-46fd62e4b66d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65860326, 0.34139674],\n",
              "       [0.67013545, 0.32986455],\n",
              "       [0.88332096, 0.11667904],\n",
              "       ...,\n",
              "       [0.69124738, 0.30875262],\n",
              "       [0.85118248, 0.14881752],\n",
              "       [0.5683676 , 0.4316324 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.best_estimator_.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIQIdWah1aDm",
        "outputId": "f2b962df-348a-4834-faa2-f23110a0f598"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test\n",
        "y_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "6kZcHGOl1hK_",
        "outputId": "32950fc6-ca8d-4947-99cb-5d91d4ff75a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1219    0\n",
              "3260    0\n",
              "1472    0\n",
              "1966    0\n",
              "3638    0\n",
              "       ..\n",
              "2427    0\n",
              "2741    0\n",
              "1993    0\n",
              "3415    0\n",
              "5036    0\n",
              "Name: V86, Length: 2911, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V86</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1219</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3638</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2427</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2741</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5036</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2911 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = precision_score(y_true, y_pred)\n",
        "r = recall_score(y_true, y_pred)\n",
        "f = fbeta_score(y_true, y_pred, beta = 2)\n",
        "print('Respective Precision, Recall and Fbeta scores are: p=%.3f, r=%.3f, f=%.3f' % (p, r, f))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smMMm2Bu1r-U",
        "outputId": "11de570b-fea5-44df-f7f5-cc09ddd2d9cf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respective Precision, Recall and Fbeta scores are: p=0.128, r=0.506, f=0.318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_pred).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "ow718NqlPxA0",
        "outputId": "548016d1-68b2-4295-ea6e-2152f078a6b2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2224\n",
              "1     687\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutoffs=np.linspace(0.001,0.999,999)"
      ],
      "metadata": {
        "id": "v90TfrHx_6za"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fbetas=[]"
      ],
      "metadata": {
        "id": "r3ffeWGk5vzF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cutoff in cutoffs:\n",
        "  predicted=(train_score>cutoff)[:,1].astype(int)\n",
        "  fbetas.append(fbeta_score(y_train, predicted, beta=2))"
      ],
      "metadata": {
        "id": "KYzcvWxw5vwh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fbetas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wa8Vcl35vt3",
        "outputId": "385e8758-29b3-491c-80d7-cbdf838ea13e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24119767119489882,\n",
              " 0.24126455906821964,\n",
              " 0.24126455906821964,\n",
              " 0.24126455906821964,\n",
              " 0.24153248195446975,\n",
              " 0.24159955567897806,\n",
              " 0.24193548387096775,\n",
              " 0.24200278164116829,\n",
              " 0.24220489977728285,\n",
              " 0.24240735580941766,\n",
              " 0.2426101505856107,\n",
              " 0.24274553571428573,\n",
              " 0.24274553571428573,\n",
              " 0.24294889695615748,\n",
              " 0.24308466051969824,\n",
              " 0.2434247341913822,\n",
              " 0.24376576071728775,\n",
              " 0.2442448062886019,\n",
              " 0.24472573839662448,\n",
              " 0.24500140805406928,\n",
              " 0.2452085682074408,\n",
              " 0.24583215597626448,\n",
              " 0.2461799660441426,\n",
              " 0.2466685568471789,\n",
              " 0.24701873935264054,\n",
              " 0.24751066856330015,\n",
              " 0.24807527801539778,\n",
              " 0.24835854981444477,\n",
              " 0.24899828277046365,\n",
              " 0.2492836676217765,\n",
              " 0.2500718597298074,\n",
              " 0.25057603686635943,\n",
              " 0.2510822510822511,\n",
              " 0.2512998266897747,\n",
              " 0.2515905147484095,\n",
              " 0.25210084033613445,\n",
              " 0.2525399129172714,\n",
              " 0.2529805175923234,\n",
              " 0.2534965034965035,\n",
              " 0.2543116047939199,\n",
              " 0.2554315913094539,\n",
              " 0.25603296056503827,\n",
              " 0.25625920471281294,\n",
              " 0.256788665879575,\n",
              " 0.257930625555885,\n",
              " 0.2585438335809807,\n",
              " 0.25900565644537066,\n",
              " 0.2594691321204891,\n",
              " 0.2600896860986547,\n",
              " 0.26102610261026105,\n",
              " 0.26165413533834586,\n",
              " 0.2622851974675912,\n",
              " 0.2629193109700816,\n",
              " 0.2637162776598969,\n",
              " 0.264277035236938,\n",
              " 0.2645985401459854,\n",
              " 0.26548672566371684,\n",
              " 0.2657299938912645,\n",
              " 0.26613643315998775,\n",
              " 0.26695305308376804,\n",
              " 0.2676923076923077,\n",
              " 0.26810477657935283,\n",
              " 0.26851851851851855,\n",
              " 0.2689335394126739,\n",
              " 0.2696002479082739,\n",
              " 0.2703542573026725,\n",
              " 0.27102803738317754,\n",
              " 0.27221526908635796,\n",
              " 0.2727272727272727,\n",
              " 0.2738432483474976,\n",
              " 0.2747079254815283,\n",
              " 0.27514231499051234,\n",
              " 0.2759276879162702,\n",
              " 0.2765416401780038,\n",
              " 0.27733503347146954,\n",
              " 0.2781329923273657,\n",
              " 0.279204107830552,\n",
              " 0.2803738317757009,\n",
              " 0.28091701646754924,\n",
              " 0.281644545160246,\n",
              " 0.2821011673151751,\n",
              " 0.2826510721247563,\n",
              " 0.28329534353630736,\n",
              " 0.2844066688460281,\n",
              " 0.28524590163934427,\n",
              " 0.2857142857142857,\n",
              " 0.28618421052631576,\n",
              " 0.28665568369028005,\n",
              " 0.2871287128712871,\n",
              " 0.2881748923484598,\n",
              " 0.2885572139303483,\n",
              " 0.28903654485049834,\n",
              " 0.2897102897102897,\n",
              " 0.2904841402337229,\n",
              " 0.29106724657075944,\n",
              " 0.2917505030181087,\n",
              " 0.29224051058112194,\n",
              " 0.29292929292929293,\n",
              " 0.2938196555217832,\n",
              " 0.29441624365482233,\n",
              " 0.2946156451066712,\n",
              " 0.2950152594099695,\n",
              " 0.29541595925297115,\n",
              " 0.29611980939414567,\n",
              " 0.29692832764505117,\n",
              " 0.2978432043820609,\n",
              " 0.29825162838532737,\n",
              " 0.29866117404737386,\n",
              " 0.2997932460372157,\n",
              " 0.3008298755186722,\n",
              " 0.3016643550624133,\n",
              " 0.30250347705146036,\n",
              " 0.30303030303030304,\n",
              " 0.30345308685036626,\n",
              " 0.30483531885073584,\n",
              " 0.30579964850615116,\n",
              " 0.30601477312697856,\n",
              " 0.30633802816901406,\n",
              " 0.30709495234733497,\n",
              " 0.30774672798019104,\n",
              " 0.30905861456483125,\n",
              " 0.3096085409252669,\n",
              " 0.3108252947481243,\n",
              " 0.3125,\n",
              " 0.31385281385281383,\n",
              " 0.31487513572204123,\n",
              " 0.31567489114658925,\n",
              " 0.3164787195343761,\n",
              " 0.3172866520787746,\n",
              " 0.3187980945401246,\n",
              " 0.3191489361702128,\n",
              " 0.31985294117647056,\n",
              " 0.3206782159970512,\n",
              " 0.3215077605321508,\n",
              " 0.3223416080029641,\n",
              " 0.32305978462681023,\n",
              " 0.32354034957233174,\n",
              " 0.3236607142857143,\n",
              " 0.3247480403135498,\n",
              " 0.3252336448598131,\n",
              " 0.32384874578809436,\n",
              " 0.324577861163227,\n",
              " 0.3254326561324304,\n",
              " 0.32604598567659254,\n",
              " 0.3267850396675482,\n",
              " 0.3271558245083207,\n",
              " 0.32740348221044663,\n",
              " 0.3280242700037922,\n",
              " 0.32864741641337386,\n",
              " 0.32877232991258076,\n",
              " 0.3295238095238095,\n",
              " 0.33040488922841865,\n",
              " 0.33129069322098814,\n",
              " 0.3319263238679969,\n",
              " 0.3326923076923077,\n",
              " 0.3333333333333333,\n",
              " 0.33371913580246915,\n",
              " 0.33423493044822256,\n",
              " 0.33449342614075794,\n",
              " 0.335401318340442,\n",
              " 0.3341103341103341,\n",
              " 0.33450019447685725,\n",
              " 0.33515198752922837,\n",
              " 0.3358063256540414,\n",
              " 0.3364632237871675,\n",
              " 0.33699059561128525,\n",
              " 0.33751962323390894,\n",
              " 0.33831628638867034,\n",
              " 0.33925049309664695,\n",
              " 0.34005535784895213,\n",
              " 0.34072900158478603,\n",
              " 0.34086405073325404,\n",
              " 0.34167659912594356,\n",
              " 0.34181240063593005,\n",
              " 0.3430394894295971,\n",
              " 0.34159009188973233,\n",
              " 0.34186325469812073,\n",
              " 0.34296028880866425,\n",
              " 0.34364951768488744,\n",
              " 0.34392598551890585,\n",
              " 0.3444802578565673,\n",
              " 0.3451756156641098,\n",
              " 0.34545454545454546,\n",
              " 0.345873786407767,\n",
              " 0.3449675324675325,\n",
              " 0.34595034595034596,\n",
              " 0.347080440996325,\n",
              " 0.3482179434657927,\n",
              " 0.3490759753593429,\n",
              " 0.35066006600660066,\n",
              " 0.3516756309474555,\n",
              " 0.352112676056338,\n",
              " 0.3522585992540406,\n",
              " 0.3525508087930319,\n",
              " 0.35357737104825293,\n",
              " 0.35387177352206495,\n",
              " 0.35505430242272346,\n",
              " 0.35609551738583994,\n",
              " 0.35804549283909015,\n",
              " 0.35864978902953587,\n",
              " 0.3588011819333052,\n",
              " 0.3598645215918713,\n",
              " 0.3604749787955895,\n",
              " 0.36154827732879624,\n",
              " 0.36216446527481894,\n",
              " 0.3627827571489543,\n",
              " 0.3635585970915312,\n",
              " 0.3644939965694683,\n",
              " 0.36496350364963503,\n",
              " 0.3662214562688496,\n",
              " 0.36732929991356955,\n",
              " 0.36812472932005197,\n",
              " 0.3682842287694974,\n",
              " 0.368763557483731,\n",
              " 0.36908380373425964,\n",
              " 0.3694046066927423,\n",
              " 0.370047888550283,\n",
              " 0.370047888550283,\n",
              " 0.37134119702927043,\n",
              " 0.37231712658782307,\n",
              " 0.373134328358209,\n",
              " 0.37142857142857144,\n",
              " 0.37257495590828926,\n",
              " 0.37372843874391865,\n",
              " 0.3742249778565102,\n",
              " 0.3752220248667851,\n",
              " 0.37622439893143367,\n",
              " 0.3775692582663092,\n",
              " 0.37790697674418605,\n",
              " 0.37583892617449666,\n",
              " 0.37668161434977576,\n",
              " 0.37803780378037805,\n",
              " 0.3787195671776375,\n",
              " 0.379746835443038,\n",
              " 0.38009049773755654,\n",
              " 0.3804347826086957,\n",
              " 0.3811252268602541,\n",
              " 0.3802367941712204,\n",
              " 0.38093065693430656,\n",
              " 0.3819762122598353,\n",
              " 0.3830275229357798,\n",
              " 0.38355535140101055,\n",
              " 0.38443830570902393,\n",
              " 0.38550323176361956,\n",
              " 0.3856812933025404,\n",
              " 0.38621646623496764,\n",
              " 0.3863951874132346,\n",
              " 0.3874709976798144,\n",
              " 0.38855281526291297,\n",
              " 0.3889147647880764,\n",
              " 0.3903693314633006,\n",
              " 0.39183481933364617,\n",
              " 0.39331135186057464,\n",
              " 0.3915094339622642,\n",
              " 0.390625,\n",
              " 0.3909952606635071,\n",
              " 0.39155196962505934,\n",
              " 0.3921102661596958,\n",
              " 0.3932316491897045,\n",
              " 0.39417104634495936,\n",
              " 0.3953042644944897,\n",
              " 0.3942307692307692,\n",
              " 0.39575289575289574,\n",
              " 0.3942912433478471,\n",
              " 0.3948643410852713,\n",
              " 0.3964007782101167,\n",
              " 0.39659367396593675,\n",
              " 0.3977550024402147,\n",
              " 0.39853300733496333,\n",
              " 0.398923152227117,\n",
              " 0.3997057381069152,\n",
              " 0.40108267716535434,\n",
              " 0.4026679841897233,\n",
              " 0.40366518078256564,\n",
              " 0.4040654437283094,\n",
              " 0.4048683556880278,\n",
              " 0.40567446490791437,\n",
              " 0.40439340988517225,\n",
              " 0.4047976011994003,\n",
              " 0.40520260130065033,\n",
              " 0.4033066132264529,\n",
              " 0.40492957746478875,\n",
              " 0.4057459677419355,\n",
              " 0.4048582995951417,\n",
              " 0.40609137055837563,\n",
              " 0.4073319755600815,\n",
              " 0.40837161817253703,\n",
              " 0.40899795501022496,\n",
              " 0.4094165813715456,\n",
              " 0.41046690610569525,\n",
              " 0.41109969167523125,\n",
              " 0.41237113402061853,\n",
              " 0.4132231404958678,\n",
              " 0.4149377593360996,\n",
              " 0.4151530877010898,\n",
              " 0.4162330905306972,\n",
              " 0.41688379364252215,\n",
              " 0.4173187271778821,\n",
              " 0.4192872117400419,\n",
              " 0.42016806722689076,\n",
              " 0.4226096143687269,\n",
              " 0.420857596611964,\n",
              " 0.42197452229299365,\n",
              " 0.42309739222990955,\n",
              " 0.42445274959957285,\n",
              " 0.42359249329758714,\n",
              " 0.42404723564143854,\n",
              " 0.4251883745963401,\n",
              " 0.42587601078167114,\n",
              " 0.42772062804547917,\n",
              " 0.4279523293607801,\n",
              " 0.42958129418162044,\n",
              " 0.42958129418162044,\n",
              " 0.4305177111716621,\n",
              " 0.430987452264048,\n",
              " 0.4314582195521573,\n",
              " 0.43240284619594965,\n",
              " 0.433589462129528,\n",
              " 0.434304562946674,\n",
              " 0.43502202643171806,\n",
              " 0.43694690265486724,\n",
              " 0.4388888888888889,\n",
              " 0.43913285158421345,\n",
              " 0.43937708565072303,\n",
              " 0.44060234244283325,\n",
              " 0.4420817011751539,\n",
              " 0.4428251121076233,\n",
              " 0.44307347167694894,\n",
              " 0.4445694991558807,\n",
              " 0.44532130777903045,\n",
              " 0.4465799886941775,\n",
              " 0.4478458049886621,\n",
              " 0.44835414301929627,\n",
              " 0.44627629334849345,\n",
              " 0.4472934472934473,\n",
              " 0.4490846681922197,\n",
              " 0.44463568559954103,\n",
              " 0.44591484464902187,\n",
              " 0.447201384881708,\n",
              " 0.4479768786127168,\n",
              " 0.4487550665894615,\n",
              " 0.45005807200929154,\n",
              " 0.4503195816385822,\n",
              " 0.45215869311551926,\n",
              " 0.45295149035651666,\n",
              " 0.45401288810779145,\n",
              " 0.45534665099882493,\n",
              " 0.45615067686874633,\n",
              " 0.4569575471698113,\n",
              " 0.4583086930810171,\n",
              " 0.45724465558194777,\n",
              " 0.4577883472057075,\n",
              " 0.4583333333333333,\n",
              " 0.4594272076372315,\n",
              " 0.46107784431137727,\n",
              " 0.4624624624624625,\n",
              " 0.4630186410102225,\n",
              " 0.4641350210970464,\n",
              " 0.4625151148730351,\n",
              " 0.46307506053268765,\n",
              " 0.461445051608986,\n",
              " 0.46200607902735563,\n",
              " 0.4631322364411944,\n",
              " 0.463980463980464,\n",
              " 0.46511627906976744,\n",
              " 0.46568627450980393,\n",
              " 0.4662576687116564,\n",
              " 0.4665438919582566,\n",
              " 0.4691358024691358,\n",
              " 0.47058823529411764,\n",
              " 0.4717566728739913,\n",
              " 0.4720496894409938,\n",
              " 0.4723430702299565,\n",
              " 0.4723430702299565,\n",
              " 0.4735202492211838,\n",
              " 0.47276142767689416,\n",
              " 0.47335423197492166,\n",
              " 0.4736511919698871,\n",
              " 0.4748427672955975,\n",
              " 0.47574039067422813,\n",
              " 0.47724399494311,\n",
              " 0.4778481012658228,\n",
              " 0.47966963151207115,\n",
              " 0.47740292807129214,\n",
              " 0.47740292807129214,\n",
              " 0.4789272030651341,\n",
              " 0.4798464491362764,\n",
              " 0.4746632456703015,\n",
              " 0.47527296082209375,\n",
              " 0.47680412371134023,\n",
              " 0.4783451842275372,\n",
              " 0.4775828460038986,\n",
              " 0.4752604166666667,\n",
              " 0.47619047619047616,\n",
              " 0.47416612164813604,\n",
              " 0.4747871643745907,\n",
              " 0.4769736842105263,\n",
              " 0.4782321899736148,\n",
              " 0.47918043621943157,\n",
              " 0.4804506295559973,\n",
              " 0.4810882548108825,\n",
              " 0.4823685961410512,\n",
              " 0.48527443105756357,\n",
              " 0.4862508383635144,\n",
              " 0.4865771812080537,\n",
              " 0.48723118279569894,\n",
              " 0.48953409858203917,\n",
              " 0.49052774018944517,\n",
              " 0.49085985104942453,\n",
              " 0.48846675712347354,\n",
              " 0.48705722070844687,\n",
              " 0.48738922972051807,\n",
              " 0.4883879781420765,\n",
              " 0.4890560875512996,\n",
              " 0.49039780521262005,\n",
              " 0.49208534067446663,\n",
              " 0.49276361130255,\n",
              " 0.49310344827586206,\n",
              " 0.4958391123439667,\n",
              " 0.4958391123439667,\n",
              " 0.4965277777777778,\n",
              " 0.49825783972125437,\n",
              " 0.4989532449406839,\n",
              " 0.5007002801120448,\n",
              " 0.5014025245441796,\n",
              " 0.5024595924104006,\n",
              " 0.5,\n",
              " 0.5007052186177715,\n",
              " 0.5021216407355021,\n",
              " 0.5021216407355021,\n",
              " 0.5031892274982283,\n",
              " 0.5042613636363636,\n",
              " 0.5046197583511016,\n",
              " 0.5028530670470756,\n",
              " 0.5039313795568263,\n",
              " 0.5050143266475645,\n",
              " 0.5021520803443329,\n",
              " 0.5025125628140703,\n",
              " 0.5035971223021583,\n",
              " 0.5043227665706052,\n",
              " 0.5054151624548736,\n",
              " 0.5072463768115942,\n",
              " 0.5076142131979695,\n",
              " 0.5083514887436456,\n",
              " 0.5087209302325582,\n",
              " 0.509090909090909,\n",
              " 0.5094614264919942,\n",
              " 0.5102040816326531,\n",
              " 0.5116959064327485,\n",
              " 0.5131964809384164,\n",
              " 0.5158437730287398,\n",
              " 0.5162241887905604,\n",
              " 0.5181347150259067,\n",
              " 0.5189028910303929,\n",
              " 0.5208333333333334,\n",
              " 0.5190440627333831,\n",
              " 0.5198204936424832,\n",
              " 0.5217717717717718,\n",
              " 0.5221637866265966,\n",
              " 0.5229495861550038,\n",
              " 0.5207547169811321,\n",
              " 0.5197268588770865,\n",
              " 0.5197268588770865,\n",
              " 0.520516717325228,\n",
              " 0.5237003058103975,\n",
              " 0.524904214559387,\n",
              " 0.5257099002302379,\n",
              " 0.5230769230769231,\n",
              " 0.5246913580246914,\n",
              " 0.5283605283605284,\n",
              " 0.5252918287937743,\n",
              " 0.5265210608424337,\n",
              " 0.5269320843091335,\n",
              " 0.528169014084507,\n",
              " 0.5289968652037618,\n",
              " 0.5335968379446641,\n",
              " 0.5344418052256532,\n",
              " 0.535289452815226,\n",
              " 0.535289452815226,\n",
              " 0.5338645418326693,\n",
              " 0.5342902711323764,\n",
              " 0.5351437699680511,\n",
              " 0.5364291433146517,\n",
              " 0.5385852090032154,\n",
              " 0.5390185036202735,\n",
              " 0.5398871877518131,\n",
              " 0.536723163841808,\n",
              " 0.5380258899676376,\n",
              " 0.5384615384615384,\n",
              " 0.5397727272727273,\n",
              " 0.540650406504065,\n",
              " 0.5415309446254072,\n",
              " 0.5419722901385493,\n",
              " 0.5446355446355446,\n",
              " 0.5464256368118324,\n",
              " 0.5436573311367381,\n",
              " 0.5441055234954658,\n",
              " 0.5454545454545454,\n",
              " 0.5422185430463576,\n",
              " 0.5435684647302904,\n",
              " 0.5403158769742311,\n",
              " 0.540765391014975,\n",
              " 0.5421184320266889,\n",
              " 0.5392976588628763,\n",
              " 0.5402010050251256,\n",
              " 0.5424726661059714,\n",
              " 0.5429292929292929,\n",
              " 0.5429292929292929,\n",
              " 0.5443037974683544,\n",
              " 0.5456852791878173,\n",
              " 0.54614733276884,\n",
              " 0.5470737913486005,\n",
              " 0.5480033984706882,\n",
              " 0.5446808510638298,\n",
              " 0.5413469735720375,\n",
              " 0.5413469735720375,\n",
              " 0.5413469735720375,\n",
              " 0.5418088737201365,\n",
              " 0.5436643835616438,\n",
              " 0.5407725321888412,\n",
              " 0.5412371134020618,\n",
              " 0.5397236614853195,\n",
              " 0.5397236614853195,\n",
              " 0.5406574394463668,\n",
              " 0.5415944540727903,\n",
              " 0.5386620330147698,\n",
              " 0.5391304347826087,\n",
              " 0.5400696864111498,\n",
              " 0.5380577427821522,\n",
              " 0.5399473222124671,\n",
              " 0.5404217926186292,\n",
              " 0.5413732394366197,\n",
              " 0.5447298494242693,\n",
              " 0.5452127659574468,\n",
              " 0.5427046263345195,\n",
              " 0.5427046263345195,\n",
              " 0.5396966993755575,\n",
              " 0.5401785714285714,\n",
              " 0.5376344086021505,\n",
              " 0.54005400540054,\n",
              " 0.5410279531109107,\n",
              " 0.5384615384615384,\n",
              " 0.5394378966455122,\n",
              " 0.5399274047186933,\n",
              " 0.5404178019981835,\n",
              " 0.5388127853881278,\n",
              " 0.536697247706422,\n",
              " 0.5371900826446281,\n",
              " 0.5345622119815668,\n",
              " 0.5360443622920518,\n",
              " 0.5319148936170213,\n",
              " 0.5287569573283859,\n",
              " 0.5260707635009311,\n",
              " 0.5260707635009311,\n",
              " 0.5228758169934641,\n",
              " 0.5238540692235735,\n",
              " 0.5248359887535146,\n",
              " 0.5211267605633803,\n",
              " 0.522107243650047,\n",
              " 0.5245746691871456,\n",
              " 0.5250709555345316,\n",
              " 0.5255681818181818,\n",
              " 0.5218216318785579,\n",
              " 0.5175688509021842,\n",
              " 0.5185537583254044,\n",
              " 0.5195424213536701,\n",
              " 0.5157593123209169,\n",
              " 0.5167464114832536,\n",
              " 0.5177372962607862,\n",
              " 0.5192307692307693,\n",
              " 0.5202312138728323,\n",
              " 0.5207328833172613,\n",
              " 0.5222437137330754,\n",
              " 0.5227492739593417,\n",
              " 0.5184108527131783,\n",
              " 0.5150631681243926,\n",
              " 0.5165692007797271,\n",
              " 0.517578125,\n",
              " 0.5131964809384164,\n",
              " 0.5093046033300686,\n",
              " 0.5058939096267191,\n",
              " 0.5019685039370079,\n",
              " 0.4990118577075099,\n",
              " 0.49204771371769385,\n",
              " 0.4935194416749751,\n",
              " 0.4904904904904905,\n",
              " 0.4909819639278557,\n",
              " 0.49147442326980945,\n",
              " 0.4919678714859438,\n",
              " 0.4879275653923541,\n",
              " 0.48940464177598386,\n",
              " 0.48632218844984804,\n",
              " 0.486815415821501,\n",
              " 0.48223350253807107,\n",
              " 0.4832146490335707,\n",
              " 0.4841997961264016,\n",
              " 0.48767967145790553,\n",
              " 0.4886831275720165,\n",
              " 0.4855371900826446,\n",
              " 0.4860392967942089,\n",
              " 0.48704663212435234,\n",
              " 0.48805815160955346,\n",
              " 0.4890738813735692,\n",
              " 0.4895833333333333,\n",
              " 0.48589341692789967,\n",
              " 0.48589341692789967,\n",
              " 0.4869109947643979,\n",
              " 0.4869109947643979,\n",
              " 0.4831932773109244,\n",
              " 0.4831932773109244,\n",
              " 0.48523206751054854,\n",
              " 0.4878048780487805,\n",
              " 0.48404255319148937,\n",
              " 0.4855923159018143,\n",
              " 0.4817987152034261,\n",
              " 0.48283261802575106,\n",
              " 0.478494623655914,\n",
              " 0.478494623655914,\n",
              " 0.47413793103448276,\n",
              " 0.47413793103448276,\n",
              " 0.46976241900647947,\n",
              " 0.46976241900647947,\n",
              " 0.4702702702702703,\n",
              " 0.4707792207792208,\n",
              " 0.46688382193268185,\n",
              " 0.4673913043478261,\n",
              " 0.46789989118607184,\n",
              " 0.46789989118607184,\n",
              " 0.46397379912663755,\n",
              " 0.4644808743169399,\n",
              " 0.4649890590809628,\n",
              " 0.4654983570646221,\n",
              " 0.46255506607929514,\n",
              " 0.46306504961411243,\n",
              " 0.459070796460177,\n",
              " 0.46008869179600886,\n",
              " 0.46008869179600886,\n",
              " 0.46008869179600886,\n",
              " 0.4550499445061043,\n",
              " 0.45,\n",
              " 0.45,\n",
              " 0.45050055617352613,\n",
              " 0.4510022271714922,\n",
              " 0.4510022271714922,\n",
              " 0.45302013422818793,\n",
              " 0.45352743561030234,\n",
              " 0.4438202247191011,\n",
              " 0.43968432919954903,\n",
              " 0.4350282485875706,\n",
              " 0.43552036199095023,\n",
              " 0.4365079365079365,\n",
              " 0.43132803632236094,\n",
              " 0.4280821917808219,\n",
              " 0.4228571428571429,\n",
              " 0.4228571428571429,\n",
              " 0.4238258877434135,\n",
              " 0.41379310344827586,\n",
              " 0.4032258064516129,\n",
              " 0.39792387543252594,\n",
              " 0.3988439306358382,\n",
              " 0.3988439306358382,\n",
              " 0.3988439306358382,\n",
              " 0.39443155452436196,\n",
              " 0.3953488372093023,\n",
              " 0.3958090803259604,\n",
              " 0.3962703962703963,\n",
              " 0.396732788798133,\n",
              " 0.39135514018691586,\n",
              " 0.391812865497076,\n",
              " 0.39273153575615477,\n",
              " 0.38777908343125733,\n",
              " 0.38823529411764707,\n",
              " 0.3828032979976443,\n",
              " 0.38325471698113206,\n",
              " 0.37825059101654845,\n",
              " 0.37825059101654845,\n",
              " 0.3732227488151659,\n",
              " 0.37410926365795727,\n",
              " 0.36904761904761907,\n",
              " 0.3694874851013111,\n",
              " 0.3708133971291866,\n",
              " 0.37170263788968827,\n",
              " 0.3614457831325301,\n",
              " 0.35714285714285715,\n",
              " 0.35714285714285715,\n",
              " 0.3575757575757576,\n",
              " 0.3575757575757576,\n",
              " 0.3575757575757576,\n",
              " 0.35844471445929527,\n",
              " 0.3597560975609756,\n",
              " 0.3601953601953602,\n",
              " 0.3501228501228501,\n",
              " 0.35141800246609123,\n",
              " 0.35315985130111527,\n",
              " 0.34782608695652173,\n",
              " 0.34782608695652173,\n",
              " 0.3482587064676617,\n",
              " 0.3482587064676617,\n",
              " 0.3482587064676617,\n",
              " 0.34869240348692404,\n",
              " 0.34869240348692404,\n",
              " 0.33707865168539325,\n",
              " 0.33125,\n",
              " 0.32540675844806005,\n",
              " 0.32075471698113206,\n",
              " 0.3148614609571788,\n",
              " 0.3148614609571788,\n",
              " 0.31525851197982346,\n",
              " 0.31525851197982346,\n",
              " 0.30973451327433627,\n",
              " 0.30973451327433627,\n",
              " 0.3037974683544304,\n",
              " 0.3037974683544304,\n",
              " 0.3037974683544304,\n",
              " 0.3037974683544304,\n",
              " 0.29860228716645487,\n",
              " 0.29860228716645487,\n",
              " 0.29860228716645487,\n",
              " 0.2997448979591837,\n",
              " 0.30089628681177977,\n",
              " 0.30128205128205127,\n",
              " 0.2952503209242619,\n",
              " 0.28957528957528955,\n",
              " 0.2838709677419355,\n",
              " 0.2788586251621271,\n",
              " 0.2669270833333333,\n",
              " 0.2607561929595828,\n",
              " 0.2607561929595828,\n",
              " 0.26143790849673204,\n",
              " 0.2617801047120419,\n",
              " 0.2621231979030144,\n",
              " 0.24967148488830487,\n",
              " 0.25,\n",
              " 0.2437417654808959,\n",
              " 0.23746701846965698,\n",
              " 0.2311756935270806,\n",
              " 0.2311756935270806,\n",
              " 0.23148148148148148,\n",
              " 0.23178807947019867,\n",
              " 0.23178807947019867,\n",
              " 0.22606382978723405,\n",
              " 0.2197070572569907,\n",
              " 0.2072192513368984,\n",
              " 0.2072192513368984,\n",
              " 0.2072192513368984,\n",
              " 0.2072192513368984,\n",
              " 0.2074966532797858,\n",
              " 0.20107238605898123,\n",
              " 0.20134228187919462,\n",
              " 0.20134228187919462,\n",
              " 0.20134228187919462,\n",
              " 0.1954177897574124,\n",
              " 0.1954177897574124,\n",
              " 0.1954177897574124,\n",
              " 0.1954177897574124,\n",
              " 0.1954177897574124,\n",
              " 0.1954177897574124,\n",
              " 0.1891891891891892,\n",
              " 0.1891891891891892,\n",
              " 0.18267929634641408,\n",
              " 0.18267929634641408,\n",
              " 0.17615176151761516,\n",
              " 0.17639077340569878,\n",
              " 0.1771117166212534,\n",
              " 0.1771117166212534,\n",
              " 0.1771117166212534,\n",
              " 0.17053206002728513,\n",
              " 0.17053206002728513,\n",
              " 0.17076502732240437,\n",
              " 0.17076502732240437,\n",
              " 0.17099863201094392,\n",
              " 0.1643835616438356,\n",
              " 0.1643835616438356,\n",
              " 0.1646090534979424,\n",
              " 0.1646090534979424,\n",
              " 0.16483516483516483,\n",
              " 0.15818431911966988,\n",
              " 0.15818431911966988,\n",
              " 0.15818431911966988,\n",
              " 0.15818431911966988,\n",
              " 0.1584022038567493,\n",
              " 0.1584022038567493,\n",
              " 0.1584022038567493,\n",
              " 0.1590594744121715,\n",
              " 0.1523545706371191,\n",
              " 0.14563106796116504,\n",
              " 0.14563106796116504,\n",
              " 0.14563106796116504,\n",
              " 0.14563106796116504,\n",
              " 0.14563106796116504,\n",
              " 0.14563106796116504,\n",
              " 0.13212795549374132,\n",
              " 0.13212795549374132,\n",
              " 0.12534818941504178,\n",
              " 0.12534818941504178,\n",
              " 0.12534818941504178,\n",
              " 0.11854951185495119,\n",
              " 0.11854951185495119,\n",
              " 0.11173184357541899,\n",
              " 0.1048951048951049,\n",
              " 0.1048951048951049,\n",
              " 0.1048951048951049,\n",
              " 0.1048951048951049,\n",
              " 0.1048951048951049,\n",
              " 0.1048951048951049,\n",
              " 0.10504201680672269,\n",
              " 0.10504201680672269,\n",
              " 0.10504201680672269,\n",
              " 0.10504201680672269,\n",
              " 0.10504201680672269,\n",
              " 0.10504201680672269,\n",
              " 0.09817671809256662,\n",
              " 0.09817671809256662,\n",
              " 0.09817671809256662,\n",
              " 0.09817671809256662,\n",
              " 0.09129213483146068,\n",
              " 0.09129213483146068,\n",
              " 0.09129213483146068,\n",
              " 0.09129213483146068,\n",
              " 0.09142053445850915,\n",
              " 0.09142053445850915,\n",
              " 0.08450704225352113,\n",
              " 0.08450704225352113,\n",
              " 0.08450704225352113,\n",
              " 0.07062146892655367,\n",
              " 0.06364922206506365,\n",
              " 0.06364922206506365,\n",
              " 0.06364922206506365,\n",
              " 0.06373937677053824,\n",
              " 0.06373937677053824,\n",
              " 0.06373937677053824,\n",
              " 0.06373937677053824,\n",
              " 0.06373937677053824,\n",
              " 0.06382978723404255,\n",
              " 0.06382978723404255,\n",
              " 0.06382978723404255,\n",
              " 0.056818181818181816,\n",
              " 0.056818181818181816,\n",
              " 0.049786628733997154,\n",
              " 0.042735042735042736,\n",
              " 0.042735042735042736,\n",
              " 0.03566333808844508,\n",
              " 0.03566333808844508,\n",
              " 0.03566333808844508,\n",
              " 0.03566333808844508,\n",
              " 0.03566333808844508,\n",
              " 0.02857142857142857,\n",
              " 0.02857142857142857,\n",
              " 0.02145922746781116,\n",
              " 0.014326647564469915,\n",
              " 0.014326647564469915,\n",
              " 0.014326647564469915,\n",
              " 0.014326647564469915,\n",
              " 0.014326647564469915,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.007173601147776184,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Grid Search Best Estimator parameters to final pipeline"
      ],
      "metadata": {
        "id": "HJSyqapK_hmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe = Pipeline(steps = [\n",
        "    ('column_transformer', column_tf), ('smote', smtt), ('PCA', pca2), ('classifier', lgbm.LGBMClassifier(device=\"gpu\", boosting_type = 'gbdt', learning_rate = 0.01, n_estimators= 300, max_bin = 63, max_depth = -1, bagging_fraction = 0.5, min_child_samples = 1, num_leaves = 15, class_weight = class_weights, classifier__reg_lambda = 1))\n",
        "])"
      ],
      "metadata": {
        "id": "ncRi7YStRK4O"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "K9U48gqISVnt",
        "outputId": "5774d984-a6da-4ba3-f13c-933dd540734a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: classifier__reg_lambda\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] Unknown parameter: classifier__reg_lambda\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Info] Number of positive: 2733, number of negative: 2733\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 5466, number of used features: 15\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 15 dense feature groups (0.08 MB) transferred to GPU in 0.000474 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478431 -> initscore=-0.086328\n",
            "[LightGBM] [Info] Start training from score -0.086328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('column_transformer',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('impute',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['V2', 'V3', 'V4', 'V6', 'V7',\n",
              "                                                   'V8', 'V9', 'V10', 'V11',\n",
              "                                                   'V12', 'V13', 'V14', 'V15',\n",
              "                                                   'V16', 'V17', 'V18', 'V19',\n",
              "                                                   'V20', 'V21', 'V22', 'V23',\n",
              "                                                   'V24', 'V25', 'V26', 'V27',\n",
              "                                                   'V28', 'V29', 'V30', 'V31',\n",
              "                                                   'V32', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(step...\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot_encoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['V1', 'V5'])])),\n",
              "                ('smote', SMOTETomek(random_state=42)),\n",
              "                ('PCA', PCA(n_components=15)),\n",
              "                ('classifier',\n",
              "                 LGBMClassifier(bagging_fraction=0.5,\n",
              "                                class_weight={0: 1.33, 1: 1.22},\n",
              "                                classifier__reg_lambda=1, device='gpu',\n",
              "                                learning_rate=0.01, max_bin=63,\n",
              "                                min_child_samples=1, n_estimators=300,\n",
              "                                num_leaves=15))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(step...\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)),\n",
              "                (&#x27;PCA&#x27;, PCA(n_components=15)),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 LGBMClassifier(bagging_fraction=0.5,\n",
              "                                class_weight={0: 1.33, 1: 1.22},\n",
              "                                classifier__reg_lambda=1, device=&#x27;gpu&#x27;,\n",
              "                                learning_rate=0.01, max_bin=63,\n",
              "                                min_child_samples=1, n_estimators=300,\n",
              "                                num_leaves=15))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;,\n",
              "                                                   &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,\n",
              "                                                   &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                                   &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;,\n",
              "                                                   &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;,\n",
              "                                                   &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                                   &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;,\n",
              "                                                   &#x27;V32&#x27;, ...]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(step...\n",
              "                                                                   SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                                  (&#x27;onehot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;V1&#x27;, &#x27;V5&#x27;])])),\n",
              "                (&#x27;smote&#x27;, SMOTETomek(random_state=42)),\n",
              "                (&#x27;PCA&#x27;, PCA(n_components=15)),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 LGBMClassifier(bagging_fraction=0.5,\n",
              "                                class_weight={0: 1.33, 1: 1.22},\n",
              "                                classifier__reg_lambda=1, device=&#x27;gpu&#x27;,\n",
              "                                learning_rate=0.01, max_bin=63,\n",
              "                                min_child_samples=1, n_estimators=300,\n",
              "                                num_leaves=15))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>column_transformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
              "                                  &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;,\n",
              "                                  &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;,\n",
              "                                  &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
              "                                  &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, ...]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;constant&#x27;)),\n",
              "                                                 (&#x27;onehot_encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;V1&#x27;, &#x27;V5&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;, &#x27;V29&#x27;, &#x27;V30&#x27;, &#x27;V31&#x27;, &#x27;V32&#x27;, &#x27;V33&#x27;, &#x27;V34&#x27;, &#x27;V35&#x27;, &#x27;V36&#x27;, &#x27;V37&#x27;, &#x27;V38&#x27;, &#x27;V39&#x27;, &#x27;V40&#x27;, &#x27;V41&#x27;, &#x27;V42&#x27;, &#x27;V43&#x27;, &#x27;V44&#x27;, &#x27;V45&#x27;, &#x27;V46&#x27;, &#x27;V47&#x27;, &#x27;V48&#x27;, &#x27;V49&#x27;, &#x27;V50&#x27;, &#x27;V51&#x27;, &#x27;V52&#x27;, &#x27;V53&#x27;, &#x27;V54&#x27;, &#x27;V55&#x27;, &#x27;V56&#x27;, &#x27;V57&#x27;, &#x27;V58&#x27;, &#x27;V59&#x27;, &#x27;V60&#x27;, &#x27;V61&#x27;, &#x27;V62&#x27;, &#x27;V63&#x27;, &#x27;V64&#x27;, &#x27;V65&#x27;, &#x27;V66&#x27;, &#x27;V67&#x27;, &#x27;V68&#x27;, &#x27;V69&#x27;, &#x27;V70&#x27;, &#x27;V71&#x27;, &#x27;V72&#x27;, &#x27;V73&#x27;, &#x27;V74&#x27;, &#x27;V75&#x27;, &#x27;V76&#x27;, &#x27;V77&#x27;, &#x27;V78&#x27;, &#x27;V79&#x27;, &#x27;V80&#x27;, &#x27;V81&#x27;, &#x27;V82&#x27;, &#x27;V83&#x27;, &#x27;V84&#x27;, &#x27;V85&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V5&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTETomek</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTETomek(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=15)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.5, class_weight={0: 1.33, 1: 1.22},\n",
              "               classifier__reg_lambda=1, device=&#x27;gpu&#x27;, learning_rate=0.01,\n",
              "               max_bin=63, min_child_samples=1, n_estimators=300,\n",
              "               num_leaves=15)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = final_pipe.predict(df_test)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcPKSIHO_FeP",
        "outputId": "885062c2-8df6-49bf-f465-23a0ef7d6aa4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: classifier__reg_lambda\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3aiyDdbHXg_",
        "outputId": "c2e2e7c3-937f-484f-d8db-1aed78c12902"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(predictions).value_counts()"
      ],
      "metadata": {
        "id": "WqdxF7ufTu9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "c0c03dac-e09d-457c-a33b-889f77d043b4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3146\n",
              "1     854\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submissions = pd.DataFrame({'V86':predictions})"
      ],
      "metadata": {
        "id": "HgUA7VB-CYk9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissions.to_csv('proj_submission.csv',index=False)"
      ],
      "metadata": {
        "id": "kDvdJsCDpsSt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UF8_MBL6qB4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}